{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab3 Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSmSNJhcOEUu"
      },
      "source": [
        "**1. (i) In this simple assignment, you will implement a single layered perceptron algorithm. You will need to write in a language of your choice\n",
        "from SCRATCH (use of pre-built machine learning libraries is not allowed though you can use basic linear algebra routines from numpy\n",
        "and scipy). (ii) Then use the MNIST dataset to find the accuracy that\n",
        "a single layered perceptron that you have implemented gives. Note the\n",
        "MNIST dataset requires classification into one of 10 categories (digits). You may assume that the class indicated is given by the output\n",
        "of the corresponding neuron with the highest output. Use 5-fold cross\n",
        "validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNYI9Qr549yK"
      },
      "source": [
        "\n",
        "#Importing Libraries\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6SvZbab4N5y"
      },
      "source": [
        "def InitializeWeights(n,m): # Where n is the no of input features and m is the no of Classes\n",
        "  W = np.random.randn(m, n)\n",
        "  return W"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u_ejUf79YFk"
      },
      "source": [
        "def Activation(h):\n",
        "  result = 1 / ( 1 + np.exp(-h))\n",
        "  return result\n",
        "\n",
        "def ActivationDerivative(h):\n",
        "  result = Activation(h)*(1 - Activation(h))\n",
        "  return result\n"
      ],
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvlqzGba6e20"
      },
      "source": [
        "def ForwardPass(sample,W):\n",
        "  m = len(W)\n",
        "  predicted = [0]*m\n",
        "  h = [0]*m\n",
        "  for i in range(0,m):\n",
        "      h[i] = W[i].T @ sample\n",
        "      predicted[i] = Activation(h[i])\n",
        "  return h,predicted\n"
      ],
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__LIs8zI_7Dg"
      },
      "source": [
        "def UpdateWeights(sample,m,n,learning_rate,label,W,del_W):\n",
        "  # To update weights based on the gradients\n",
        "  h,predicted = ForwardPass(sample,W)\n",
        "  for i in range(0,m):\n",
        "    for j in range(0,n):\n",
        "      J_W = 2 * (predicted[i]-label[i]) * sample[j]\n",
        "      del_W[i][j] = del_W[i][j]  - (learning_rate * J_W)\n",
        "  return del_W\n"
      ],
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C30aAZQZIxvI"
      },
      "source": [
        "def SingleLayerPerceptron(train,label,learning_rate,epochs):\n",
        "  n = len(train[0]) # No.of.input features\n",
        "  m = len(label[0]) # No.of classes\n",
        "  \n",
        "  W = InitializeWeights(n,m) #Initialsing weights to random values\n",
        "  \n",
        "  for i in range(0,epochs):\n",
        "    del_W = np.zeros((m, n))\n",
        "    for j in range(0,len(train)):\n",
        "      del_W = UpdateWeights(train[j],m,n,learning_rate,label[j],W,del_W)\n",
        "    W = W + del_W\n",
        "  return W\n",
        "  "
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uvx0N_yIW5H"
      },
      "source": [
        "#loading MNIST dataset\n",
        "\n",
        "mnist = datasets.load_digits()\n",
        "m_data = mnist.data\n",
        "\n",
        "# One-hot encoding of the target\n",
        "y = []\n",
        "for i in mnist.target:\n",
        "  L = [1  if i == j else 0 for j in range(10)]\n",
        "  y.append(L)\n",
        "\n",
        "# Adding 1 at the beginning of each input array for bias\n",
        "X =[]\n",
        "for i in range(len(m_data)):\n",
        "  X.append(np.concatenate([[1],m_data[i]]))"
      ],
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgvtO1kKfPRq"
      },
      "source": [
        "# To calculate the accuracy of the model\n",
        "def CalculateScore(test,label,W_predict):\n",
        "  sum = 0\n",
        "  #CM =[[0]*10 for _ in range(10)] : To print confusion matrix if required\n",
        "  for i in range(len(test)):\n",
        "    a,b = ForwardPass(test[i],W_predict)\n",
        "    max_prob = max(b)\n",
        "    predicted_value = b.index(max_prob)\n",
        "    #CM[label[i].index(1)][predicted_value] += 1 : To print confusion matrix if required\n",
        "    if label[i].index(1) == predicted_value:\n",
        "      sum = sum + 1\n",
        "  #print(\"CONFUSION MATRIX : \\n\",np.matrix(CM)) : To print confusion matrix if required\n",
        "  return sum/len(test) "
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgmX5Z9fMCDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0097c0ee-5519-4ee9-ef16-4c3c78156219"
      },
      "source": [
        "# Finding accuracy of the model using 5-fold Cross Validation\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0) \n",
        "score = 0\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "    X_train = [];X_test = [];y_train =[];y_test =[]\n",
        "    print(\"Processing a split of Train and Test data\")\n",
        "    for i in train_index:\n",
        "      X_train.append(X[i])\n",
        "      y_train.append(y[i])\n",
        "    for j in test_index:\n",
        "      X_test.append(X[j])\n",
        "      y_test.append(y[j])\n",
        "    W_predict = SingleLayerPerceptron(X_train,y_train,0.1,10)\n",
        "    s = CalculateScore(X_test,y_test,W_predict)\n",
        "    print(\"Score:\",s)\n",
        "    score += s\n",
        "print(\"Average Accuracy:\",(score/5)*100,\"%\")"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing a split of Train and Test data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.7388888888888889\n",
            "Processing a split of Train and Test data\n",
            "Score: 0.7694444444444445\n",
            "Processing a split of Train and Test data\n",
            "Score: 0.6861111111111111\n",
            "Processing a split of Train and Test data\n",
            "Score: 0.7305555555555555\n",
            "Processing a split of Train and Test data\n",
            "Score: 0.7305555555555555\n",
            "Average Accuracy: 73.11111111111111 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyBKFLchNwYi"
      },
      "source": [
        "**2. For this part you can use scikit (or any other pre-packaged library)\n",
        "and use their built-in implementation of multi-layered perceptron. Use\n",
        "the same dataset as above. Use 5-fold cross validation as above and\n",
        "compare your results with what you get with a single layered perceptron**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q13bLv49NvZa"
      },
      "source": [
        "mnist = datasets.load_digits()\n",
        "X = mnist.data\n",
        "y = mnist.target"
      ],
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6NeQwJJNvqu",
        "outputId": "5a9312b9-8aec-457d-cd0a-b13c46e71f3b"
      },
      "source": [
        "# Classification using the sklearn MLP classifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes = (100),activation='logistic',learning_rate='constant', learning_rate_init=0.001, max_iter=3000)\n",
        "L = cross_val_score(clf, X, y, cv=5)\n",
        "print(\"Average accuracy with a Multilayered Perceptron:\",sum(L)/5)\n",
        "\n",
        "# Cross-Validaton using Stratified Split\n",
        "\n",
        "score = 0\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0) \n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  clf.fit(X_train,y_train)\n",
        "  score += clf.score(X_test,y_test)\n",
        "print(\"Average accuracy with a Multilayered Perceptron (using stratified split):\" , (score*100)/5,\"%\")"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy with a Multilayered Perceptron: 0.9432466728567007\n",
            "Average accuracy with a Multilayered Perceptron (using stratified split): 97.61111111111111 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9t6Yup9ci6e"
      },
      "source": [
        "**From the above models, we can see that the accuracy obtained using a Multilayer perceptron is  significantly higher than the accuracy obtained using a Single Layer perceptron.** \n"
      ]
    }
  ]
}